---

- name: Add OpenJDK-r repository
  apt_repository:
    repo: 'ppa:openjdk-r/ppa'
  when: ansible_distribution == 'Ubuntu' and ansible_lsb.major_release|int <= 15 and not skip_packages|default(False) and not use_oracle_java|default(False)

- block:
  - name: Add Oracle Java WebUpd8 repository
    apt_repository:
       repo: 'ppa:webupd8team/java'

  - name: Accept Oracle license
    debconf:
      name: "{{ java_package }} "
      question: "shared/accepted-oracle-license-v1-1"
      value: "true"
      vtype: "select"
  when: use_oracle_java| default(False) and not skip_packages|default(False)

- name: Select Java option to install (OpenJDK)
  include_vars:
      file: group_vars/all/openjdk.yml
  when: not use_oracle_java|default(False)

- name: Select Java option to install (Oracle)
  include_vars:
      file: group_vars/all/oracle.yml
  when: use_oracle_java|default(False)


- name: update apt cache
  apt: update_cache=yes
  when: not skip_packages|default(False)
  retries: 2

- name: install packages
  package: name={{ item }} state=present
  with_items: "{{ ubuntu_packages }}"
  when: not skip_packages|default(False)

- name: install Java
  package: name={{ java_package }} state=present
  when: not skip_packages|default(False)

- name: disable net.ipv6.conf.all.disable_ipv6
  sysctl: name=net.ipv6.conf.all.disable_ipv6 value=1 state=present
  tags:
    - prepare

- name: disable net.ipv4.tcp_syncookies
  sysctl: name=net.ipv4.tcp_syncookies value=1 state=present
  tags:
    - prepare

- name: disable net.ipv4.conf.default.accept_source_route
  sysctl: name=net.ipv4.conf.default.accept_source_route value=0 state=present
  tags:
    - prepare

- name: disable net.ipv4.tcp_tw_recycle
  sysctl: name=net.ipv4.tcp_tw_recycle value=1 state=present
  tags:
    - prepare

- name: disable net.ipv4.ip_forward
  sysctl: name=net.ipv4.tcp_syncookies value=0 state=present
  tags:
    - prepare

- name: disable net.ipv4.tcp_max_syn_backlog
  sysctl: name=net.ipv4.tcp_max_syn_backlog value=4096 state=present
  tags:
    - prepare

- name: disable net.ipv4.conf.all.arp_filter
  sysctl: name=net.ipv4.conf.all.arp_filter value=1 state=present
  tags:
    - prepare

- name: disable net.ipv4.ip_local_port_range
  sysctl: name=net.ipv4.ip_local_port_range value='1025 65535' state=present
  tags:
    - prepare

- name: net.core.netdev_max_backlog
  sysctl: name=net.core.netdev_max_backlog value=10000 state=present
  tags:
    - prepare

- name: net.core.rmem_max
  sysctl: name=net.core.rmem_max value=2097152 state=present
  tags:
    - prepare

- name: net.core.wmem_max
  sysctl: name=net.core.wmem_max value=2097152 state=present
  tags:
    - prepare

- name: vm.overcommit_memory
  sysctl: name=vm.overcommit_memory value=1 state=present
  tags:
    - prepare

- name: kernel.shmmax
  sysctl: name=kernel.shmmax value=500000000 state=present
  tags:
    - prepare

- name: kernel.shmmni
  sysctl: name=kernel.shmmni value=4096 state=present
  tags:
    - prepare

- name: kernel.shmall
  sysctl: name=kernel.shmall value=4000000000 state=present
  tags:
    - prepare

- name: kernel.sysrq
  sysctl: name=kernel.sem value=1 state=present
  tags:
    - prepare

- name: kernel.sem
  sysctl: name=kernel.sem value='250 512000 100 2048' state=present
  tags:
    - prepare

- name: disable net.ipv6.conf.lo.disable_ipv6
  sysctl: name=net.ipv6.conf.lo.disable_ipv6 value=1 state=present
  tags:
    - prepare

- name: increase hard file limits
  pam_limits: domain=* limit_type=hard limit_item=nofile value=131093
  tags:
    - prepare

- name: increase proc hard limits
  pam_limits: domain=* limit_type=hard limit_item=nproc value=131072
  tags:
    - prepare

- name: increase proc hard limits
  pam_limits: domain=* limit_type=soft limit_item=nproc value=131072
  tags:
    - prepare

- name: increase soft file limits
  pam_limits: domain=* limit_type=soft limit_item=nofile value=131093

- name: create hadoop group
  group: name=hadoop state=present
  tags:
    - prepare

- name: create hadoop user
  user: name={{ hadoop_user }} comment="Hadoop user" group=hadoop shell=/bin/bash
  tags:
    - prepare

- name: get Hadoop distro (except CDH4)
  get_url: url={{ hadoop_download_url }} dest=/usr/local/ checksum="md5:{{ hadoop_md5 }}"
  when: "'{{ inventory_hostname }}' == '{{ active_master_inventory_hostname }}' and {{ hadoop_version }} != 'cdh4'"

- name: get Hadoop distro (CDH4)
  get_url: url={{ hadoop_download_url }} dest=/usr/local/
  when: "'{{ inventory_hostname }}' == '{{ active_master_inventory_hostname }}' and {{ hadoop_version }} == 'cdh4'"


- name: distribute hadoop among slaves
  synchronize:
    src: "/usr/local/{{ hadoop_file }}.tar.gz"
    dest: "/usr/local/{{ hadoop_file }}.tar.gz"
    checksum: yes
  delegate_to: "{{ active_master_inventory_hostname }}"

- name: unzip hadoop
  unarchive: copy=no src=/usr/local/{{ hadoop_file }}.tar.gz dest=/usr/local/ owner={{ hadoop_user }} group=hadoop

- name: create hadoop symlink
  file: src=/usr/local/{{ hadoop_file }} dest=/usr/local/hadoop state=link


- name: put needed swift library
  get_url: url={{ swift_download_url }} dest=/usr/local/{{ hadoop_file }}/share/hadoop/hdfs/lib/
  when: "{{ hadoop_version }} == 2.3 or {{ hadoop_version }} == 2.4 or {{ hadoop_version }} == 2.6 or {{ hadoop_version }} == 2.7"

#- name: remove hadoop archive
#  file: path=/usr/local/{{ hadoop_file }}.tar.gz state=absent

- name: set user and priviliges on hadoop
  file: path=/usr/local/{{ hadoop_file }} owner={{ hadoop_user }} group=hadoop recurse=yes

- name: get Spark distro
  get_url: url={{ spark_download_url }} dest=/opt/ checksum="md5:{{ spark_md5 }}"
  when: "'{{ inventory_hostname }}' == '{{ active_master_inventory_hostname }}'"

#- name: put spark distro to master
#  copy: src={{ spark_arch }} dest=/opt/
#  when: "'{{ inventory_hostname }}' == '{{ active_master_inventory_hostname }}'"

- name: distribute spark distro among slaves
  synchronize:
    src: "/opt/{{ spark_file }}.tgz"
    dest: "/opt/{{ spark_file }}.tgz"
    checksum: yes
  delegate_to: "{{ active_master_inventory_hostname }}"

- name: unzip spark
  unarchive: copy=no src=/opt/{{ spark_file }}.tgz dest=/opt

#- name: remove spark archive
#  file: path=/opt/{{ spark_file }}.tgz state=absent

- name: create spark symlink
  file: src={{ spark_home }} dest=/opt/spark state=link

- name: create spark symlink
  file: src={{ spark_home }} dest=/usr/local/spark state=link


- name: create extra jars directory
  file: path={{ spark_extra_jars_dir }} owner={{ hadoop_user }} group=hadoop state=directory

- name: copy extra jars
  copy: src={{item.path}} dest={{ spark_extra_jars_dir }}/{{item.name}} owner={{ hadoop_user }} group=hadoop mode=0644
  with_items: "{{extra_jars}}"

